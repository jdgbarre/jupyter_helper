{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Machine Learning Supervised"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions MLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "from sklearn.model_selection import (cross_val_score, train_test_split)\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "#\n",
    "def split_set(X, y, test_size=0.33, random_state_value=5):\n",
    "    \n",
    "    return train_test_split(X, y, test_size=test_size, \n",
    "                            random_state=random_state_value)\n",
    "\n",
    "#\n",
    "def ml_getting(model, param, X_train, y_train, X_test, y_test):\n",
    "    \n",
    "    ml_model = model(**param)\n",
    "    \n",
    "    ml_model.fit(X_train, y_train.values.ravel())\n",
    "    ml_predict = ml_model.predict(X_test)\n",
    "    ml_rmse = math.sqrt(\n",
    "        mean_squared_error(ml_predict, y_test.values.ravel()))\n",
    "    \n",
    "    ml_scores = cross_val_score(ml_model, X_test, y_test.values.ravel()).mean() \n",
    "    \n",
    "    return [model.__name__, param, ml_rmse, ml_scores]\n",
    "\n",
    "#\n",
    "def ml_run(models, parameters, X, y):\n",
    "    \n",
    "    X_train, X_test, y_train, y_test = split_set(X, y)\n",
    "    \n",
    "    outputs = []\n",
    "    for i, model in enumerate(models):\n",
    "        for param in parameters[i]:\n",
    "            try:\n",
    "                outputs.append(\n",
    "                    ml_getting(model, param, X_train, y_train, X_test, y_test)\n",
    "                )\n",
    "            except ValueError:\n",
    "                print('# ValueError:')\n",
    "                print(model)\n",
    "                print(param)\n",
    "                print()\n",
    "            \n",
    "    return outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns; sns.set()\n",
    "\n",
    "def plot_sgdclassifier(X, y, clf_fit):\n",
    "    \n",
    "    plt.figure()\n",
    "    \n",
    "    h = .02  # step size in the mesh\n",
    "    \n",
    "    # create a mesh to plot in\n",
    "    x_min, x_max = X[:, 0].min() - 1, X[:, 0].max() + 1\n",
    "    y_min, y_max = X[:, 1].min() - 1, X[:, 1].max() + 1\n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n",
    "                         np.arange(y_min, y_max, h))\n",
    "\n",
    "    # Plot the decision boundary. For that, we will assign a color to each\n",
    "    # point in the mesh [x_min, x_max]x[y_min, y_max].\n",
    "    Z = clf_fit.predict(np.c_[xx.ravel(), yy.ravel()])\n",
    "    # Put the result into a color plot\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    cs = plt.contourf(xx, yy, Z, cmap=plt.cm.Paired)\n",
    "    plt.axis('tight')\n",
    "\n",
    "    # Plot also the training points\n",
    "    label_y = np.unique(y)\n",
    "    for i, color in zip(clf.classes_, colors):\n",
    "        idx = np.where(y == i)\n",
    "        plt.scatter(X[idx, 0], X[idx, 1], c=color, label=label_y[i],\n",
    "                    cmap=plt.cm.Paired, edgecolor='black', s=20)\n",
    "    plt.title(\"Decision surface of multi-class SGD\")\n",
    "    plt.axis('tight')\n",
    "\n",
    "    # Plot the three one-against-all classifiers\n",
    "    xmin, xmax = plt.xlim()\n",
    "    ymin, ymax = plt.ylim()\n",
    "    coef = clf_fit.coef_\n",
    "    intercept = clf_fit.intercept_\n",
    "\n",
    "    def plot_hyperplane(c, color):\n",
    "        def line(x0):\n",
    "            return (-(x0 * coef[c, 0]) - intercept[c]) / coef[c, 1]\n",
    "\n",
    "        plt.plot([xmin, xmax], [line(xmin), line(xmax)],\n",
    "                 ls=\"--\", color=color)\n",
    "\n",
    "    for i, color in zip(clf_fit.classes_, colors):\n",
    "        plot_hyperplane(i, color)\n",
    "        \n",
    "    plt.legend()\n",
    "        \n",
    "    plt.show();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_iris\n",
    "from sklearn.linear_model import (SGDClassifier, LogisticRegression)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generation parameters for models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iteration = [100, 200, 500]\n",
    "models = [LogisticRegression, SGDClassifier]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGDClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.SGDClassifier.html\n",
    "\n",
    "## Parameter names\n",
    "sgd_param_name = ['loss', 'penalty']\n",
    "\n",
    "## Diferents elements by parameter name\n",
    "sgd_loss = ['hinge', 'log', 'modified_huber', 'squared_hinge', 'perceptron', 'squared_loss', 'huber', 'epsilon_insensitive', 'squared_epsilon_insensitive']\n",
    "sgd_penalty = ['none', 'l2', 'l1', 'elasticnet']\n",
    "\n",
    "## Generate list with dict type with configurate paramenter\n",
    "sgd_param = [{'loss' : i, 'penalty' : j} for i in sgd_loss for j in sgd_penalty]\n",
    "[x.update({'max_iter' : y}) for y in max_iteration for x in sgd_param]\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html#sklearn.linear_model.LogisticRegression\n",
    "## Parameter names\n",
    "lr_param_name = ['penalty', 'solver']\n",
    "\n",
    "## Diferents elements by parameter name\n",
    "lr_penalty = ['l2', 'l1']\n",
    "lr_solver = ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga']\n",
    "\n",
    "## Generate list with dict type with configurate paramenter\n",
    "lr_param = [{'solver' : i, 'penalty' : j} for i in lr_solver for j in lr_penalty]\n",
    "[x.update({'max_iter' : y}) for y in max_iteration for x in lr_param]\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters config for LR and SGD\n",
    "parameters = [lr_param, sgd_param]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading data\n",
    "\n",
    "def change(number):\n",
    "    try:\n",
    "        return iris.target_names[number]\n",
    "    except IndexError:\n",
    "        return \"error\"\n",
    "\n",
    "df_iris = pd.DataFrame(load_iris().data, columns = load_iris().feature_names)\n",
    "df_iris.columns = ['sepal_length', 'sepal_width','petal_length', 'petalal_width']\n",
    "iris = load_iris()\n",
    "iris_target = pd.DataFrame(iris.target, columns=['target'])#.applymap(change)\n",
    "\n",
    "df = pd.concat([df_iris, iris_target], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ValueError:\n",
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "{'solver': 'newton-cg', 'penalty': 'l1', 'max_iter': 500}\n",
      "\n",
      "# ValueError:\n",
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "{'solver': 'lbfgs', 'penalty': 'l1', 'max_iter': 500}\n",
      "\n",
      "# ValueError:\n",
      "<class 'sklearn.linear_model.logistic.LogisticRegression'>\n",
      "{'solver': 'sag', 'penalty': 'l1', 'max_iter': 500}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jdgonzalez/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/jdgonzalez/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/jdgonzalez/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/jdgonzalez/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/jdgonzalez/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/jdgonzalez/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/jdgonzalez/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/jdgonzalez/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/jdgonzalez/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n",
      "/Users/jdgonzalez/miniconda3/lib/python3.6/site-packages/sklearn/linear_model/sag.py:326: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  \"the coef_ did not converge\", ConvergenceWarning)\n"
     ]
    }
   ],
   "source": [
    "# Run models\n",
    "outputs = ml_run(models, parameters, df_iris, iris_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>parameters</th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'perceptron', 'penalty': 'none', 'max...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.924837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'log', 'penalty': 'none', 'max_iter':...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.924837</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'modified_huber', 'penalty': 'l1', 'm...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.906318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'squared_hinge', 'penalty': 'none', '...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.906318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'perceptron', 'penalty': 'l1', 'max_i...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.906318</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'solver': 'liblinear', 'penalty': 'l2', 'max_...</td>\n",
       "      <td>0.244949</td>\n",
       "      <td>0.905229</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'hinge', 'penalty': 'none', 'max_iter...</td>\n",
       "      <td>0.244949</td>\n",
       "      <td>0.900000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'solver': 'lbfgs', 'penalty': 'l2', 'max_iter...</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.896296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'solver': 'newton-cg', 'penalty': 'l2', 'max_...</td>\n",
       "      <td>0.141421</td>\n",
       "      <td>0.896296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'solver': 'liblinear', 'penalty': 'l1', 'max_...</td>\n",
       "      <td>0.282843</td>\n",
       "      <td>0.885621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'modified_huber', 'penalty': 'none', ...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.884096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'hinge', 'penalty': 'l1', 'max_iter':...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.884096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'log', 'penalty': 'l1', 'max_iter': 500}</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.883007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'solver': 'sag', 'penalty': 'l2', 'max_iter':...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.880392</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'solver': 'saga', 'penalty': 'l1', 'max_iter'...</td>\n",
       "      <td>0.282843</td>\n",
       "      <td>0.860784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>{'solver': 'saga', 'penalty': 'l2', 'max_iter'...</td>\n",
       "      <td>0.244949</td>\n",
       "      <td>0.860784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'perceptron', 'penalty': 'l2', 'max_i...</td>\n",
       "      <td>0.244949</td>\n",
       "      <td>0.843355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'hinge', 'penalty': 'l2', 'max_iter':...</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.839651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'squared_hinge', 'penalty': 'l1', 'ma...</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.835948</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'squared_hinge', 'penalty': 'l2', 'ma...</td>\n",
       "      <td>0.282843</td>\n",
       "      <td>0.827451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'perceptron', 'penalty': 'elasticnet'...</td>\n",
       "      <td>0.282843</td>\n",
       "      <td>0.800436</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'modified_huber', 'penalty': 'elastic...</td>\n",
       "      <td>0.316228</td>\n",
       "      <td>0.783007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'modified_huber', 'penalty': 'l2', 'm...</td>\n",
       "      <td>0.244949</td>\n",
       "      <td>0.783007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'log', 'penalty': 'elasticnet', 'max_...</td>\n",
       "      <td>0.244949</td>\n",
       "      <td>0.781917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'hinge', 'penalty': 'elasticnet', 'ma...</td>\n",
       "      <td>0.282843</td>\n",
       "      <td>0.758170</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'squared_hinge', 'penalty': 'elasticn...</td>\n",
       "      <td>0.374166</td>\n",
       "      <td>0.755991</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'log', 'penalty': 'l2', 'max_iter': 500}</td>\n",
       "      <td>0.244949</td>\n",
       "      <td>0.721569</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'huber', 'penalty': 'none', 'max_iter...</td>\n",
       "      <td>1.256981</td>\n",
       "      <td>0.646841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'huber', 'penalty': 'l1', 'max_iter':...</td>\n",
       "      <td>0.509902</td>\n",
       "      <td>0.586057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'huber', 'penalty': 'l2', 'max_iter':...</td>\n",
       "      <td>0.424264</td>\n",
       "      <td>0.563834</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'epsilon_insensitive', 'penalty': 'el...</td>\n",
       "      <td>0.812404</td>\n",
       "      <td>0.469499</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'epsilon_insensitive', 'penalty': 'l1...</td>\n",
       "      <td>1.272792</td>\n",
       "      <td>0.456427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'squared_epsilon_insensitive', 'penal...</td>\n",
       "      <td>1.272792</td>\n",
       "      <td>0.437908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'squared_epsilon_insensitive', 'penal...</td>\n",
       "      <td>0.812404</td>\n",
       "      <td>0.418301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'huber', 'penalty': 'elasticnet', 'ma...</td>\n",
       "      <td>0.424264</td>\n",
       "      <td>0.413943</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'epsilon_insensitive', 'penalty': 'no...</td>\n",
       "      <td>1.272792</td>\n",
       "      <td>0.395425</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'squared_loss', 'penalty': 'l2', 'max...</td>\n",
       "      <td>0.812404</td>\n",
       "      <td>0.339869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'epsilon_insensitive', 'penalty': 'l2...</td>\n",
       "      <td>1.303840</td>\n",
       "      <td>0.339869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'squared_epsilon_insensitive', 'penal...</td>\n",
       "      <td>0.883176</td>\n",
       "      <td>0.339869</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'squared_loss', 'penalty': 'none', 'm...</td>\n",
       "      <td>1.303840</td>\n",
       "      <td>0.298039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'squared_epsilon_insensitive', 'penal...</td>\n",
       "      <td>0.812404</td>\n",
       "      <td>0.286275</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'squared_loss', 'penalty': 'l1', 'max...</td>\n",
       "      <td>0.905539</td>\n",
       "      <td>0.267974</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>SGDClassifier</td>\n",
       "      <td>{'loss': 'squared_loss', 'penalty': 'elasticne...</td>\n",
       "      <td>1.303840</td>\n",
       "      <td>0.228758</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 model                                         parameters  \\\n",
       "0        SGDClassifier  {'loss': 'perceptron', 'penalty': 'none', 'max...   \n",
       "1        SGDClassifier  {'loss': 'log', 'penalty': 'none', 'max_iter':...   \n",
       "2        SGDClassifier  {'loss': 'modified_huber', 'penalty': 'l1', 'm...   \n",
       "3        SGDClassifier  {'loss': 'squared_hinge', 'penalty': 'none', '...   \n",
       "4        SGDClassifier  {'loss': 'perceptron', 'penalty': 'l1', 'max_i...   \n",
       "5   LogisticRegression  {'solver': 'liblinear', 'penalty': 'l2', 'max_...   \n",
       "6        SGDClassifier  {'loss': 'hinge', 'penalty': 'none', 'max_iter...   \n",
       "7   LogisticRegression  {'solver': 'lbfgs', 'penalty': 'l2', 'max_iter...   \n",
       "8   LogisticRegression  {'solver': 'newton-cg', 'penalty': 'l2', 'max_...   \n",
       "9   LogisticRegression  {'solver': 'liblinear', 'penalty': 'l1', 'max_...   \n",
       "10       SGDClassifier  {'loss': 'modified_huber', 'penalty': 'none', ...   \n",
       "11       SGDClassifier  {'loss': 'hinge', 'penalty': 'l1', 'max_iter':...   \n",
       "12       SGDClassifier  {'loss': 'log', 'penalty': 'l1', 'max_iter': 500}   \n",
       "13  LogisticRegression  {'solver': 'sag', 'penalty': 'l2', 'max_iter':...   \n",
       "14  LogisticRegression  {'solver': 'saga', 'penalty': 'l1', 'max_iter'...   \n",
       "15  LogisticRegression  {'solver': 'saga', 'penalty': 'l2', 'max_iter'...   \n",
       "16       SGDClassifier  {'loss': 'perceptron', 'penalty': 'l2', 'max_i...   \n",
       "17       SGDClassifier  {'loss': 'hinge', 'penalty': 'l2', 'max_iter':...   \n",
       "18       SGDClassifier  {'loss': 'squared_hinge', 'penalty': 'l1', 'ma...   \n",
       "19       SGDClassifier  {'loss': 'squared_hinge', 'penalty': 'l2', 'ma...   \n",
       "20       SGDClassifier  {'loss': 'perceptron', 'penalty': 'elasticnet'...   \n",
       "21       SGDClassifier  {'loss': 'modified_huber', 'penalty': 'elastic...   \n",
       "22       SGDClassifier  {'loss': 'modified_huber', 'penalty': 'l2', 'm...   \n",
       "23       SGDClassifier  {'loss': 'log', 'penalty': 'elasticnet', 'max_...   \n",
       "24       SGDClassifier  {'loss': 'hinge', 'penalty': 'elasticnet', 'ma...   \n",
       "25       SGDClassifier  {'loss': 'squared_hinge', 'penalty': 'elasticn...   \n",
       "26       SGDClassifier  {'loss': 'log', 'penalty': 'l2', 'max_iter': 500}   \n",
       "27       SGDClassifier  {'loss': 'huber', 'penalty': 'none', 'max_iter...   \n",
       "28       SGDClassifier  {'loss': 'huber', 'penalty': 'l1', 'max_iter':...   \n",
       "29       SGDClassifier  {'loss': 'huber', 'penalty': 'l2', 'max_iter':...   \n",
       "30       SGDClassifier  {'loss': 'epsilon_insensitive', 'penalty': 'el...   \n",
       "31       SGDClassifier  {'loss': 'epsilon_insensitive', 'penalty': 'l1...   \n",
       "32       SGDClassifier  {'loss': 'squared_epsilon_insensitive', 'penal...   \n",
       "33       SGDClassifier  {'loss': 'squared_epsilon_insensitive', 'penal...   \n",
       "34       SGDClassifier  {'loss': 'huber', 'penalty': 'elasticnet', 'ma...   \n",
       "35       SGDClassifier  {'loss': 'epsilon_insensitive', 'penalty': 'no...   \n",
       "36       SGDClassifier  {'loss': 'squared_loss', 'penalty': 'l2', 'max...   \n",
       "37       SGDClassifier  {'loss': 'epsilon_insensitive', 'penalty': 'l2...   \n",
       "38       SGDClassifier  {'loss': 'squared_epsilon_insensitive', 'penal...   \n",
       "39       SGDClassifier  {'loss': 'squared_loss', 'penalty': 'none', 'm...   \n",
       "40       SGDClassifier  {'loss': 'squared_epsilon_insensitive', 'penal...   \n",
       "41       SGDClassifier  {'loss': 'squared_loss', 'penalty': 'l1', 'max...   \n",
       "42       SGDClassifier  {'loss': 'squared_loss', 'penalty': 'elasticne...   \n",
       "\n",
       "        rmse        r2  \n",
       "0   0.200000  0.924837  \n",
       "1   0.200000  0.924837  \n",
       "2   0.200000  0.906318  \n",
       "3   0.200000  0.906318  \n",
       "4   0.200000  0.906318  \n",
       "5   0.244949  0.905229  \n",
       "6   0.244949  0.900000  \n",
       "7   0.141421  0.896296  \n",
       "8   0.141421  0.896296  \n",
       "9   0.282843  0.885621  \n",
       "10  0.200000  0.884096  \n",
       "11  0.200000  0.884096  \n",
       "12  0.200000  0.883007  \n",
       "13  0.200000  0.880392  \n",
       "14  0.282843  0.860784  \n",
       "15  0.244949  0.860784  \n",
       "16  0.244949  0.843355  \n",
       "17  0.316228  0.839651  \n",
       "18  0.200000  0.835948  \n",
       "19  0.282843  0.827451  \n",
       "20  0.282843  0.800436  \n",
       "21  0.316228  0.783007  \n",
       "22  0.244949  0.783007  \n",
       "23  0.244949  0.781917  \n",
       "24  0.282843  0.758170  \n",
       "25  0.374166  0.755991  \n",
       "26  0.244949  0.721569  \n",
       "27  1.256981  0.646841  \n",
       "28  0.509902  0.586057  \n",
       "29  0.424264  0.563834  \n",
       "30  0.812404  0.469499  \n",
       "31  1.272792  0.456427  \n",
       "32  1.272792  0.437908  \n",
       "33  0.812404  0.418301  \n",
       "34  0.424264  0.413943  \n",
       "35  1.272792  0.395425  \n",
       "36  0.812404  0.339869  \n",
       "37  1.303840  0.339869  \n",
       "38  0.883176  0.339869  \n",
       "39  1.303840  0.298039  \n",
       "40  0.812404  0.286275  \n",
       "41  0.905539  0.267974  \n",
       "42  1.303840  0.228758  "
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a DataFrame with all models and parameters as well as RMSE and R^2\n",
    "df_ml = pd.DataFrame(\n",
    "    outputs, columns=['model', 'parameters', 'rmse', 'r2']\n",
    ")\n",
    "\n",
    "df_ml.sort_values(by=['r2'], ascending=False).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_sgdclassifier(df_iris, iris_target)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
